# Fine-tuning module dependencies
# These are required for model fine-tuning using unsloth

# Core training libraries
transformers>=4.40.0
trl>=0.8.0
peft>=0.8.0
datasets>=2.14.0
accelerate>=0.24.0

# Unsloth for efficient LoRA fine-tuning
# Note: unsloth may have specific installation requirements
# See: https://github.com/unslothai/unsloth
unsloth[colab-new]>=2024.9

# Optional: for evaluation metrics
scikit-learn>=1.3.0
